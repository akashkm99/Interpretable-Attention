{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Quora Question Paraphrase (QQP) Dataset\n",
    " \n",
    "Download and extract the QQP dataset from https://gluebenchmark.com/task \n",
    "\n",
    "You should have the following files QQP/train.tsv, QQP/test.tsv, QQP/dev.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "assert os.path.exists('QQP/train.tsv') and os.path.exists('QQP/test.tsv') and os.path.exists('QQP/dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/preksha/.local/lib/python3.6/site-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "import spacy\n",
    "import re\n",
    "import random\n",
    "from random import shuffle\n",
    "import codecs\n",
    "import numpy as np\n",
    "from tasks import QQPTask\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME2INFO = {'qqp': (QQPTask, 'QQP')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(name,max_seq_len):\n",
    "    \n",
    "    task = NAME2INFO[name][0](NAME2INFO[name][1], max_seq_len, name)\n",
    "    train_data = task.train_data_text\n",
    "    \n",
    "    train = list(zip(train_data[0],train_data[1],train_data[2]))\n",
    "    total_len = len(train)\n",
    "    val_len = int(total_len*0.1)\n",
    "\n",
    "    val = list(zip(*train[:val_len]))\n",
    "    train = list(zip(*train[val_len:]))\n",
    "    test = task.val_data_text\n",
    "\n",
    "    print (\"Train datapoints\",len(train[0]))\n",
    "    print (\"Test datapoints\",len(test[0]))\n",
    "    print (\"Val datapoints\",len(val[0]))\n",
    "\n",
    "    df_paragraphs = list(train[1]) + list(test[1]) + list(val[1])\n",
    "    df_questions = list(train[0]) + list(test[0]) + list(val[0])\n",
    "    df_answers = list(train[2]) + list(test[2]) + list(val[2])\n",
    "    df_exp_splits = ['train']*len(train[0]) + ['test']*len(test[0]) + ['dev']*len(val[0])\n",
    "        \n",
    "    entity_list = [str(i) for i in np.unique(np.array(df_answers))]\n",
    "    f = open('{}/entity_list.txt'.format(NAME2INFO[name][1]), 'w')\n",
    "    f.write(\"\\n\".join(entity_list))\n",
    "    f.close()\n",
    "    df = {'paragraph' : df_paragraphs, 'question' : df_questions, 'answer' : df_answers, 'exp_split' : df_exp_splits}\n",
    "    df = pd.DataFrame(df)\n",
    "    df = df.dropna()\n",
    "    df.to_csv('{}/{}_dataset.csv'.format(NAME2INFO[name][1],name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"qqp\"\n",
    "max_seq_len=40\n",
    "preprocess(name,max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size :  26365\n",
      "entity2index {'0': 0, '1': 1}\n",
      "Found 25310 words in model out of 26365\n"
     ]
    }
   ],
   "source": [
    "data_file = '{}/{}_dataset.csv'.format(NAME2INFO[name][1],name)\n",
    "output_file = 'vec_{}.p'.format(name)\n",
    "answers_file = '{}/entity_list.txt'.format(NAME2INFO[name][1])\n",
    "\n",
    "# %run \"../preprocess_data_QA.py\" --data_file $data_file --output_file $output_file --all_answers_file $answers_file --word_vectors_type glove.840B.300d --min_df 10\n",
    "%run \"../preprocess_data_QA.py\" --data_file $data_file --output_file $output_file --all_answers_file $answers_file --word_vectors_type glove.840B.300d --min_df 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
