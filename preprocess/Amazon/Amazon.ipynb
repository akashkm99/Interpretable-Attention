{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Dataset\n",
    "\n",
    "Download and extract the 'amazon_review_full_csv.tar.gz' file from https://drive.google.com/drive/u/0/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M\n",
    "\n",
    "Make sure that 'train.csv' and 'test.csv' files are present in this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "assert os.path.exists('train.csv') and os.path.exists('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "import spacy\n",
    "import re\n",
    "import random\n",
    "import codecs \n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1357)\n",
    "def read_input_file(input_file):\n",
    "    lines = csv.reader(codecs.open(input_file, \"r\", encoding=\"utf-8\"))\n",
    "    lines = list(lines)\n",
    "    random.shuffle(lines)\n",
    "    labels, _, lines = list(zip(*lines))\n",
    "    lines = list(zip(labels, lines))\n",
    "    print (lines[:3])\n",
    "    new_labels = []\n",
    "    new_lines = []\n",
    "    for label, line in lines:\n",
    "        if int(label) < 3:\n",
    "            new_labels.append(\"0\")\n",
    "            new_lines.append(line)\n",
    "        elif int(label) > 3:\n",
    "            new_labels.append(\"1\")\n",
    "            new_lines.append(line)\n",
    "            \n",
    "    print (new_labels[:2], new_lines[:2])\n",
    "    print(len(new_labels), len(new_lines))\n",
    "    return new_labels, new_lines\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3', 'got it to add to my kindle. have no real opinion about itgood to have with me when i want to read'), ('2', \"First of all don't get me wrong I think the missions on this game are some of the best ever. But this game is NASTY there is no call for all of the half naked women and that such.... Why can't people make a game for clean half intellegent people who are above half naked women on GAMES and such. Catch that ON GAMES! I would rank this game a perfect 5 stars if it cut back on some language and the girls in it had on some what clothing. It makes me want to vomit. What kind of perv came up with the idea of doing this. There are people who would like a game like this without the cursing and sexual content. I dont appreciate the way people look at teens now. .... Gamers do not support games such as Vice City. ....\"), ('2', 'I\\'ve been a great fan of J.J. for some 25 years and possess some 15 of his albums. Also I am a great appreciator of Clapton as a guitarist but not necessarily his albums. The best way to sum this one up is to say that Clapton brings J.J. down to a level of blandness I never expected. After J.J.\\'s recent Albums, \"J.J.Cale Live\" and \"To Tulsa and Back\" (Both 5 Star Albums), this was a real disappointment.')]\n",
      "['0', '0'] [\"First of all don't get me wrong I think the missions on this game are some of the best ever. But this game is NASTY there is no call for all of the half naked women and that such.... Why can't people make a game for clean half intellegent people who are above half naked women on GAMES and such. Catch that ON GAMES! I would rank this game a perfect 5 stars if it cut back on some language and the girls in it had on some what clothing. It makes me want to vomit. What kind of perv came up with the idea of doing this. There are people who would like a game like this without the cursing and sexual content. I dont appreciate the way people look at teens now. .... Gamers do not support games such as Vice City. ....\", 'I\\'ve been a great fan of J.J. for some 25 years and possess some 15 of his albums. Also I am a great appreciator of Clapton as a guitarist but not necessarily his albums. The best way to sum this one up is to say that Clapton brings J.J. down to a level of blandness I never expected. After J.J.\\'s recent Albums, \"J.J.Cale Live\" and \"To Tulsa and Back\" (Both 5 Star Albums), this was a real disappointment.']\n",
      "2400000 2400000\n",
      "2400000\n"
     ]
    }
   ],
   "source": [
    "labels_train,  content_train = read_input_file(\"train.csv\")\n",
    "assert(len(labels_train) == len(content_train))\n",
    "print (len(labels_train))\n",
    "\n",
    "labels_dev, content_dev = labels_train[:7000], content_train[:7000]\n",
    "keys_dev = [\"dev\"]* len(labels_dev)\n",
    "\n",
    "labels_train, content_train = labels_train[7000:], content_train[7000:]\n",
    "keys_train = [\"train\"]*len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3', \"This book was enjoyable enough, but I felt like it was more like a movie script--written for mass appeal, predictable. There wasn't much depth to any of the characters. I wasn't bored, but I won't be reading it again, like I do most books I enjoy. I will probably see the movie, just because it seems like this book may be better as a movie--so I can see some emotion in the characters.\"), ('1', 'Not Pretzel Salt or even close. It is not white and course crystals; but clearish, thin and flat crytstals. Just threw out. Nothing like the great pretzel salt from Nuts.com.'), ('4', \"If you like opeth I don't see how you can't like this. Two sets plus a making of. This DVD has great sound.\")]\n",
      "['0', '1'] ['Not Pretzel Salt or even close. It is not white and course crystals; but clearish, thin and flat crytstals. Just threw out. Nothing like the great pretzel salt from Nuts.com.', \"If you like opeth I don't see how you can't like this. Two sets plus a making of. This DVD has great sound.\"]\n",
      "520000 520000\n",
      "520000\n"
     ]
    }
   ],
   "source": [
    "labels_test, content_test = read_input_file(\"test.csv\")\n",
    "keys_test = [\"test\"]*len(labels_test)\n",
    "assert(len(labels_test) == len(content_test))\n",
    "print (len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def tokenize(text) :\n",
    "    #text = \" \".join(text)\n",
    "    text = text.replace(\"-LRB-\", '')\n",
    "    text = text.replace(\"-RRB-\", \" \")\n",
    "    #text = re.sub(r'\\W', ' ', text)\n",
    "    #text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    tokens = \" \".join([t.text.lower() for t in nlp((text))])\n",
    "    return tokens\n",
    "\n",
    "labels_train = [int(i) for i in labels_train]\n",
    "content_train = [tokenize(i) for i in content_train]\n",
    "\n",
    "\n",
    "labels_test = [int(i) for i in labels_test]\n",
    "content_test = [tokenize(i) for i in content_test]\n",
    "\n",
    "\n",
    "labels_dev = [int(i) for i in labels_dev]\n",
    "content_dev = [tokenize(i) for i in content_dev]\n",
    "\n",
    "#assert(len(labels) == len(content))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_train[:3])\n",
    "print(content_train[:3])\n",
    "labels = labels_train + labels_dev + labels_test\n",
    "content = content_train + content_dev + content_test\n",
    "keys = keys_train + keys_dev + keys_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text' : content, 'label' : labels, 'exp_split' : keys})\n",
    "df.to_csv('amazon_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_train[:3])\n",
    "print(content_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size :  49907\n",
      "Found 36019 words in model out of 49907\n"
     ]
    }
   ],
   "source": [
    "%run \"../preprocess_data_BC.py\" --data_file amazon_dataset.csv --output_file ./vec_amazon.p --word_vectors_type fasttext.simple.300d --min_df 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention",
   "language": "python",
   "name": "attention"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
